\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Proofs}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Estimation error for tensor denoising}{1}{subsection.1.1}}
\newlabel{eq:property}{{1}{1}{Estimation error for tensor denoising}{equation.1.1}{}}
\MT@newlabel{eq:property}
\newlabel{eq:bound}{{2}{1}{Estimation error for tensor denoising}{equation.1.2}{}}
\newlabel{eq:taylor}{{3}{1}{Estimation error for tensor denoising}{equation.1.3}{}}
\MT@newlabel{eq:taylor}
\newlabel{eq:linear}{{4}{1}{Estimation error for tensor denoising}{equation.1.4}{}}
\MT@newlabel{eq:property}
\newlabel{eq:norm}{{5}{1}{Estimation error for tensor denoising}{equation.1.5}{}}
\newlabel{eq:normrandom}{{6}{1}{Estimation error for tensor denoising}{equation.1.6}{}}
\MT@newlabel{eq:linear}
\MT@newlabel{eq:norm}
\MT@newlabel{eq:normrandom}
\newlabel{eq:linearconclusion}{{7}{2}{Estimation error for tensor denoising}{equation.1.7}{}}
\MT@newlabel{eq:taylor}
\newlabel{eq:quadratic}{{8}{2}{Estimation error for tensor denoising}{equation.1.8}{}}
\MT@newlabel{eq:taylor}
\MT@newlabel{eq:linearconclusion}
\MT@newlabel{eq:quadratic}
\newlabel{eq:KLbound1}{{9}{2}{Estimation error for tensor denoising}{equation.1.9}{}}
\MT@newlabel{eq:KLbound1}
\newlabel{eq:KLbound}{{10}{3}{Estimation error for tensor denoising}{equation.1.10}{}}
\MT@newlabel{eq:KLbound}
\newlabel{eq:totalKL}{{11}{3}{Estimation error for tensor denoising}{equation.1.11}{}}
\MT@newlabel{eq:totalKL}
\newlabel{eq:final}{{12}{3}{Estimation error for tensor denoising}{equation.1.12}{}}
\MT@newlabel{eq:final}
\newlabel{eq:prob}{{1.1}{3}{Estimation error for tensor denoising}{equation.1.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Sample complexity for tensor completion}{3}{subsection.1.2}}
\newlabel{eq:Taylor2}{{13}{3}{Sample complexity for tensor completion}{equation.1.13}{}}
\MT@newlabel{eq:linear}
\MT@newlabel{eq:quadratic}
\newlabel{eq:linear2}{{1.2}{3}{Sample complexity for tensor completion}{Item.2}{}}
\newlabel{eq:quadratic2}{{14}{3}{Sample complexity for tensor completion}{equation.1.14}{}}
\MT@newlabel{eq:Taylor2}
\MT@newlabel{eq:quadratic2}
\newlabel{eq:sample}{{15}{3}{Sample complexity for tensor completion}{equation.1.15}{}}
\citation{brascamp2002extensions}
\MT@newlabel{eq:sample}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Convexity of the log-likelihood function}{4}{subsection.1.3}}
\newlabel{thm:convexity}{{1.1}{4}{}{thm.1.1}{}}
\newlabel{eq:function}{{16}{4}{}{equation.1.16}{}}
\MT@newlabel{eq:function}
\citation{ghadermarzy2019near}
\citation{lim2005singular}
\citation{friedland2018nuclear}
\citation{ghadermarzy2019near}
\citation{wang2017operator}
\citation{jiang2017tensor}
\newlabel{lem:lossconvexity}{{1}{5}{Corollary 3.5 in~\cite {brascamp2002extensions}}{lem.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Auxiliary lemmas}{5}{subsection.1.4}}
\newlabel{sec:lemma}{{1.4}{5}{Auxiliary lemmas}{subsection.1.4}{}}
\newlabel{lem:Mnormbound}{{2}{5}{M-norm and infinity norm~\citep {ghadermarzy2019near}}{lem.2}{}}
\newlabel{lem:nuclear}{{3}{5}{Nuclear norm and F-norm}{lem.3}{}}
\newlabel{eq:norminequality}{{17}{5}{Auxiliary lemmas}{equation.1.17}{}}
\citation{friedland2018nuclear}
\citation{nguyen2015tensor}
\citation{tomioka2014spectral}
\citation{tomioka2014spectral}
\MT@newlabel{eq:norminequality}
\newlabel{lem:inq}{{4}{6}{}{lem.4}{}}
\newlabel{lem:tensor}{{5}{6}{\cite {tomioka2014spectral}}{lem.5}{}}
\newlabel{lem:noisytensor}{{6}{6}{}{lem.6}{}}
\newlabel{lem:KLentry}{{7}{7}{}{lem.7}{}}
\newlabel{eq:KL}{{1.4}{7}{Auxiliary lemmas}{lem.7}{}}
\newlabel{lem:KL}{{8}{7}{KL divergence and F-norm}{lem.8}{}}
\MT@newlabel{eq:model}
\newlabel{eq:ass}{{18}{7}{KL divergence and F-norm}{equation.1.18}{}}
\MT@newlabel{eq:model}
\newlabel{eq:entrywise}{{19}{8}{Auxiliary lemmas}{equation.1.19}{}}
\MT@newlabel{eq:ass}
\MT@newlabel{eq:entrywise}
\newlabel{lem:construction}{{9}{8}{}{lem.9}{}}
\citation{tsybakov2009introduction}
\citation{ghadermarzy2019near}
\newlabel{lem:VGbound}{{10}{9}{Varshamov-Gilbert bound}{lem.10}{}}
\newlabel{lem:Tsybakov}{{11}{9}{Theorem 2.5 in~\cite {tsybakov2009introduction}}{lem.11}{}}
\newlabel{lem:convexity}{{12}{9}{Lemma 28 in~\cite {ghadermarzy2019near}}{lem.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Extension of Theorem\nobreakspace  {}\ref  {thm:rate} to unknown cut-off points}{10}{section.2}}
\newlabel{eq:joint}{{20}{10}{Extension of Theorem~\ref {thm:rate} to unknown cut-off points}{equation.2.20}{}}
\MT@newlabel{eq:bound}
\newlabel{eq:UL}{{21}{10}{Extension of Theorem~\ref {thm:rate} to unknown cut-off points}{equation.2.21}{}}
\newlabel{eq:CD}{{22}{10}{Extension of Theorem~\ref {thm:rate} to unknown cut-off points}{equation.2.22}{}}
\newlabel{ass:joint}{{1}{10}{}{assumption.1}{}}
\newlabel{thm:ratejoint}{{2.1}{11}{Statistical convergence with unknown $\mb $}{thm.2.1}{}}
\MT@newlabel{eq:model}
\MT@newlabel{eq:joint}
\MT@newlabel{eq:UL}
\MT@newlabel{eq:CD}
\newlabel{eq:level}{{23}{11}{Extension of Theorem~\ref {thm:rate} to unknown cut-off points}{equation.2.23}{}}
\MT@newlabel{eq:level}
\newlabel{eq:ratenew}{{2}{11}{Extension of Theorem~\ref {thm:rate} to unknown cut-off points}{equation.2.23}{}}
\newlabel{eq:property}{{24}{12}{Extension of Theorem~\ref {thm:rate} to unknown cut-off points}{equation.2.24}{}}
\newlabel{eq:taylorb}{{25}{12}{Extension of Theorem~\ref {thm:rate} to unknown cut-off points}{equation.2.25}{}}
\MT@newlabel{eq:taylorb}
\newlabel{eq:linearb}{{26}{12}{Extension of Theorem~\ref {thm:rate} to unknown cut-off points}{equation.2.26}{}}
\MT@newlabel{eq:taylorb}
\newlabel{eq:quadraticb}{{27}{12}{Extension of Theorem~\ref {thm:rate} to unknown cut-off points}{equation.2.27}{}}
\MT@newlabel{eq:taylorb}
\MT@newlabel{eq:linearb}
\MT@newlabel{eq:quadraticb}
\@writefile{toc}{\contentsline {section}{\numberline {3}Additional results on simulations}{13}{section.3}}
\MT@newlabel{eq:latent}
\@writefile{lof}{\contentsline {figure}{\numberline {{S1}}{\ignorespaces Performance comparison for predicting the median label. (a,c) Prediction errors versus sample complexity $\rho =|\Omega |/d^k$ when $L=5$. (b,d) Prediction errors versus the number of ordinal levels $L$, when $\rho =0.8.$}}{14}{figure.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Additional results on HCP analysis}{14}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Clustering based on Tucker representation}{14}{subsection.4.1}}
\newlabel{sec:clustering}{{4.1}{14}{Clustering based on Tucker representation}{subsection.4.1}{}}
\citation{kolda2009tensor}
\citation{carlson2012physiology,reed1994nature}
\newlabel{eq:Tuckerest}{{28}{15}{Clustering based on Tucker representation}{equation.4.28}{}}
\MT@newlabel{eq:Tuckerest}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Clustering results on HCP}{15}{subsection.4.2}}
\newlabel{figure:elbow}{{4.2}{15}{Clustering results on HCP}{subsection.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {{S2}}{\ignorespaces The elbow plot for the number of clusters}}{15}{figure.2}}
\newlabel{table:clustering}{{4.2}{16}{Clustering results on HCP}{figure.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {{S1}}{\ignorespaces Clustering result of brain nodes. The last alphabet in the node name indicates the left brain (`L' ) and the right brain (`R') {\color  {red} Please use node names from Github.../../BrainNetViewer\_20171031/Data/miaoyan/Desikan\_miaoyan.node.txt. Please remove the quote.} }}{16}{table.1}}
\bibstyle{plainnat}
\bibdata{tensor_wang}
\bibcite{brascamp2002extensions}{{1}{2002}{{Brascamp and Lieb}}{{}}}
\bibcite{carlson2012physiology}{{2}{2012}{{Carlson}}{{}}}
\bibcite{friedland2018nuclear}{{3}{2018}{{Friedland and Lim}}{{}}}
\bibcite{ghadermarzy2019near}{{4}{2019}{{Ghadermarzy et~al.}}{{Ghadermarzy, Plan, and Yilmaz}}}
\bibcite{jiang2017tensor}{{5}{2017}{{Jiang et~al.}}{{Jiang, Yang, and Zhang}}}
\bibcite{kolda2009tensor}{{6}{2009}{{Kolda and Bader}}{{}}}
\bibcite{lim2005singular}{{7}{2005}{{Lim}}{{}}}
\bibcite{nguyen2015tensor}{{8}{2015}{{Nguyen et~al.}}{{Nguyen, Drineas, and Tran}}}
\newlabel{figure:brain image}{{4.2}{17}{Clustering results on HCP}{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {{S3}}{\ignorespaces Averaged connection within each of the eight clusters. \textbf  {[FIXME (Miaoyan): Nodes within each cluster are connected by edges?]}}}{17}{figure.3}}
\bibcite{reed1994nature}{{9}{1994}{{Reed and Caselli}}{{}}}
\bibcite{tomioka2014spectral}{{10}{2014}{{Tomioka and Suzuki}}{{}}}
\bibcite{tsybakov2009introduction}{{11}{2009}{{Tsybakov}}{{}}}
\bibcite{wang2017operator}{{12}{2017}{{Wang et~al.}}{{Wang, Duc, Fischer, and Song}}}
